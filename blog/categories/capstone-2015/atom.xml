<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Capstone 2015 | To Boldly Code...]]></title>
  <link href="http://boldlycoding.com/blog/categories/capstone-2015/atom.xml" rel="self"/>
  <link href="http://boldlycoding.com/"/>
  <updated>2015-02-11T02:08:17-05:00</updated>
  <id>http://boldlycoding.com/</id>
  <author>
    <name><![CDATA[George McDaid]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Twitter Trends]]></title>
    <link href="http://boldlycoding.com/blog/2015/02/11/twitter-trends/"/>
    <updated>2015-02-11T01:27:08-05:00</updated>
    <id>http://boldlycoding.com/blog/2015/02/11/twitter-trends</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Twitter defines trends as those topics which are popular now, not topics which have been popular for a long period of time. During the course of my project thus far I have been tracking trends and making observations about them. One interesting observation about Twitter trends is to volatility of the trends. Trends change on a frequent basis, which suggests an instability of conversation on Twitter. It is also interesting to note the
number of trends which are not of appreciable social, political or economic significance. From January to February 2015 trends included #ReplaceAMovieTitleWithGoat, #HappyBirthdayHarryStyles, #NationalPizzaDay, #RuinAFriendshipIn5Words and a number of other One Direction topics. The instability of trends and lack of politically, socially and economically trends does pose a problem for my project. To cope with this problem I have begun tracking trends every two minutes and reviewing the trends periodically. If a significant topic does begin to trends. I will be able to start tracking that trends and then analyse the related tweets. Twitter trends are also based on location. Twitter will tailor the trends displayed based on the location of the user. My project will focus on worldwide opinions and topics so this posed another temporary problem. The Twitter API allows for the acquisition of trends on a global scale. This list of trends is not influenced by any particular user&rsquo;s information or location. Overall, Trends tend to be very complex and will continue to shape the project towards it completion.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing Cloudera Manager]]></title>
    <link href="http://boldlycoding.com/blog/2014/12/29/installing-cloudera-manager/"/>
    <updated>2014-12-29T08:47:51-05:00</updated>
    <id>http://boldlycoding.com/blog/2014/12/29/installing-cloudera-manager</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Cloudera Manager (CM) will install the Oracle JDK, CDH (runs Hadoop), and other service management software. The manager administrates many services including HDFS, YARN, ZooKeeper, Oozie, Hive, Hue, Sqoop, HBase, Impala, Solr and Spark. Many of these can be installed only if they are needed. The CM installation process includes a section to select all or a subset of the services.</p>

<ol>
<li><p>Start a tmux session with</p>

<pre><code class="`"> tmux
</code></pre>

<p> In the event of a disconnect reconnect to the machine and run</p>

<pre><code class="`"> tmux a
</code></pre>

<p> Tmux will try to attach to a previously running session.</p></li>
<li><p>Download and start the Cloudera Manager installer on the cluster manager</p>

<pre><code class="`"> wget http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
 chmod u+x cloudera-manager-installer.bin
 sudo ./cloudera-manager-installer.bin
</code></pre></li>
<li><p>If the installation was started correctly, it should display what is shown in the screenshot below. Select <em>Next</em> to continue.</p>

<p> <img class="center" src="/images/cm/3_start.PNG" width="550" height="750" title="Select next" ></p></li>
<li><p>Accept the Cloudera license</p></li>
<li><p>Accept the Oracle binary license. The installer will proceed to install the Cloudera repository, gather files, and install the JDK followed by Cloudera Manager Server. Have patience as the installation can take some time.</p></li>
<li><p>When the installer finishes, it will indicate to open a web browser and navigate to the following url: <a href="http://localhost:7180/">http://localhost:7180/</a> The default username is <strong>admin</strong> and the password is <strong>admin</strong>. Open a web browser and use a url that will connect to the appropriate node in the cluster. After logging in, the installation will continue.</p>

<p> <img class="center" src="/images/cm/6_browser.PNG" width="550" height="750" title="Open a web browser" ></p></li>
<li><p>After signing in, the CM installer will displays a comparison of the different versions. Cloudera Express supports the goals of my project, if Enterprise is selected a trial will be provided for 60 days and then all features will return to the level of Cloudera Express. After reviewing the offerings, click your desired offering and then click continue.</p></li>
<li><p>CM displays the services available, click continue.</p></li>
<li><p>Now, all the nodes in the cluster will need to be selected. To select hosts, patterns are supported. Supported patters include</p>

<pre><code class="`"> 10.1.1.[1-4] -&gt; 10.1.1.1, 10.1.1.2, 10.1.1.3, 10.1.1.4
 host[1-3].network.com -&gt; host1.network.com, host2.network.com, host3.network.com
 host[07-10].network.com -&gt; host07.network.com, host08.network.com, host09.network.com, host10.network.com
</code></pre>

<p> My cluster has three hosts, and I chose to use IP address patterns. To select all the hosts I entered</p>

<pre><code class="`"> 10.1.0.[111-113]
</code></pre>

<p> If hosts are successfully found CM should display the following after clicking search</p>

<p> <img class="center" src="/images/cm/9_hosts.PNG" width="550" height="750" title="Hosts were found" ></p>

<p> If all the hosts were found, click continue, otherwise check the entered pattern/hostnames before continuing.</p></li>
<li><p>The CM installer will now confirm repository options, the defaults should be appropriate, so just click Continue.</p>

<p><img class="center" src="/images/cm/10_repo.PNG" width="550" height="750" title="Hosts were found" ></p></li>
<li><p>Next, the installer displays the Oracle license for the JDK. Click the check box at the bottom and then click Continue. Unless needed, the check box for Java Unlimited Strength Encryption Policy files does not need to be checked.</p></li>
<li><p>The installer will now ask if services should be installed in single user mode. To simplify the installation, <strong>do not</strong> click the check box and just click continue.</p></li>
<li><p>The installer will now need root SSH credentials. Ensure that root access via SSH on all hosts is possible and enter the appropriate credentials and port number. To simplify my own installation process, I have configured all root passwords in the cluster to be the same.</p>

<p><img class="center" src="/images/cm/13_ssh.PNG" width="550" height="750" title="Enter SSH info" ></p>

<p>After clicking continue, the installer will write needed files to all hosts in the cluster.</p></li>
<li><p>After the files have been written, the installer will indicate that operations have completed successfully. Click continue. If problems were encountered, an attempt to remove CM can be made and the installation restarted.</p>

<p><img class="center" src="/images/cm/14_cis.PNG" width="550" height="750" title="Cluster install successful" ></p></li>
<li><p>CM will now download, distribute and activate parcels on all hosts. After this process is complete, click Continue.</p>

<p><img class="center" src="/images/cm/15_parcel.PNG" width="550" height="750" title="Completed parcel distribution" ></p></li>
<li><p>Finally, CM will inspect all the hosts in the cluster. I do not recommend skipping this step. It will check for many common problems. If any are found, correct them. Otherwise, click finish to complete the CM installation.</p></li>
<li><p>Now CDH 5 services need to be selected. For my project I required HDFS, Hive, Hue (A great web interface for Hadoop administration) and YARN (Oozie will also be installed since Hue requires it). To install this subset of services, click the Custom Services radio button. Select the aforementioned services, and click Continue.</p></li>
<li><p>Cloudera Manager will next require that all roles in the cluster be delegated to nodes in the cluster. The master of the cluster should run all services except the HDFS DataNode and the YARN NodeManager. This would not be done in a production cluster as it would degrade performance of the services, but it is suitable for a test cluster. Ensure the master is also running the Cloudera Management Service, this was not selected to run on any nodes during my installation, but the ACtivity Monitor is a useful service to have running. After correctly delegating all the service to the nodes, click Continue.</p></li>
<li><p>The database needs to be configured for CM and CDH services. I prefer to use a MySQL database to maintain the necessary information. To configure MySQL for CM</p>

<p>Stop MySQL</p>

<pre><code>sudo service mysql stop
</code></pre>

<p>Edit <em>/etc/my.cnf</em></p>

<pre><code>sudo nano /etc/mysql/my.cnf
</code></pre>

<p>Change the file to the following (Keeping your own hardware restrictions in mind). Also, note max_connections, in a small cluster (&lt;50 nodes) this can be set to 250. In a larger cluster this can be set to 750.</p>

<pre><code>[mysqld]
transaction-isolation=READ-COMMITTED
# Disabling symbolic-links is recommended to prevent assorted security risks;
# to do so, uncomment this line:
# symbolic-links=0

key_buffer              = 16M
key_buffer_size         = 32M
max_allowed_packet      = 16M
thread_stack            = 256K
thread_cache_size       = 8
query_cache_limit       = 8M
query_cache_size        = 32M
query_cache_type        = 1

max_connections         = 250

# log-bin should be on a disk with enough free space
#log-bin=/x/home/mysql/logs/binary/mysql_binary_log

# For MySQL version 5.1.8 or later. Comment out binlog_format for older versions.
#binlog_format           = mixed

read_buffer_size = 2M
read_rnd_buffer_size = 16M
sort_buffer_size = 8M
join_buffer_size = 8M

# InnoDB settings
innodb_file_per_table = 1
innodb_flush_log_at_trx_commit  = 2
#innodb_log_buffer_size          = 50M

#256MB for every 2GB of RAM installed
innodb_buffer_pool_size         = 256M

#innodb_thread_concurrency = 2 * (cpu cores + disks)
innodb_thread_concurrency       = 4 

innodb_flush_method             = O_DIRECT
#innodb_log_file_size = 50M

[mysqld_safe]
log-error=/var/log/mysqld.log
pid-file=/var/run/mysqld/mysqld.pid
</code></pre>

<p>Start MySQL</p>

<pre><code>sudo service mysql start
</code></pre>

<p>If MySQL fails to start, run the following for error indications
<code>
cat /var/log/mysql/error.log
</code></p>

<p>Install the MySQL JDBC connector</p>

<pre><code>sudo apt-get install libmysql-java
</code></pre>

<p>Now create the indicated databases and users (with the shown password) using the MySQL CLI or phpMyAdmin. Once everything has been created with the appropriate passwords, click Continue.</p></li>
<li></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing, Configuring and Testing Bacula]]></title>
    <link href="http://boldlycoding.com/blog/2014/12/26/installing-bacula/"/>
    <updated>2014-12-26T04:07:10-05:00</updated>
    <id>http://boldlycoding.com/blog/2014/12/26/installing-bacula</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>Installation</h2>

<p>Cloudera Manager and Hadoop installations can be unstable so having backups of the file system becomes very important. Bacula create full, incremental, and differential backups of the filesystem. It support configuration of the backed up directory and exclusions to each backup. Bacula also allows restoration of previously created backups. To create these backups, restore files properly, and maintain other internal information, Bacula requires MySQL to be installed.</p>

<ol>
<li><p>To begin the install, issue the command:</p>

<pre><code class="`"> sudo apt-get install bacula-server bacula-client
</code></pre>

<p> To simply the install process, select Yes when asked if dbconfig-common should be used. This requires entering the database administrator password.</p></li>
<li><p>Create the directories to store Bacula&rsquo;s backup and restoration files</p>

<pre><code class="`"> sudo mkdir -p /bacula/backup /bacula/restore
</code></pre>

<p> Also, change permission so Bacula create correctly read and write.</p>

<pre><code class="`"> sudo chown -R bacula:bacula /bacula
 sudo chmod -R 700 /bacula
</code></pre></li>
<li><p>Now, Bacula must be configured to backup and restore to appropriate locations. To begin, the <em>bacula-dir.conf</em> file must be edited (The next three steps edit this file as well).</p>

<pre><code class="`"> sudo nano /etc/bacula/bacula-dir.conf
</code></pre>

<p> Within the <em>Job</em> under the comment block beginning <em>Standard Restore Template</em>, change the Where setting. To restore files in their original location it should be set to /. To restore them to the previously created directory, set it to <em>/bacula/restore</em>.</p>

<p> I configured my install to restore to the original locations</p>

<pre><code class="`"> Job {
   Name = "RestoreFiles"
   Type = Restore
   Client=Blank-fd
   FileSet="Full Set"
   Storage = File
   Pool = Default
   Messages = Standard
   Where = /
 }
</code></pre></li>
<li><p>To conserve disk space, I configured Bacula to use GZIP compression. This is found in the options section of the FileSet listed under the comment <em>List of files to be backed up</em></p>

<pre><code class="`"> Include {
     Options {
         signature = MD5
         compression = GZIP
     }
 }
</code></pre></li>
<li><p>Then set file to / to back up the entire file system. This option is found after the compression option under the next comment block.</p>

<pre><code class="`"> File = /
</code></pre></li>
<li><p>Now, configure Bacula to exclude its own file path. This is found in the exclude section, which should be just beyond the file option.</p>

<pre><code class="`"> Exclude {
     File = /var/lib/bacula
     File = /bacula
     File = /proc
     File = /tmp
     File = /.journal
     File = /.fsck
 }
</code></pre></li>
<li><p>Next, Bacula must be configured to back up the files described in the Job to the appropriate location. Backup locations are defined in <em>/etc/bacula/bacula-sd.conf</em></p>

<pre><code class="`"> sudo nano /etc/bacula/bacula-sd.conf
</code></pre>

<p> Under to comment block beginning <em>Devices supported by this Storage daemon</em>, change the Device group to</p>

<pre><code class="`"> Device {
   Name = FileStorage
   Media Type = File
   Archive Device = /bacula/backup
   LabelMedia = yes;                   # lets Bacula label unlabeled media
   Random Access = Yes;
   AutomaticMount = yes;               # when device opened, read it
   RemovableMedia = no;
   AlwaysOpen = no;
 }
</code></pre>

<p> This sets the backup location to the directory created in a previous step.</p></li>
<li><p>To validate the edited configuration, two command should be issued. If no errors are found, the command will return nothing.</p>

<pre><code class="`"> sudo bacula-dir -tc /etc/bacula/bacula-dir.conf
 sudo bacula-sd -tc /etc/bacula/bacula-sd.conf
</code></pre></li>
<li><p>Now, the Bacula services must be restarted to use the new configuration.</p>

<pre><code class="`"> sudo service bacula-sd restart
 sudo service bacula-director restart
</code></pre></li>
</ol>


<h2>Testing Bacula</h2>

<ol>
<li><p>Bacula backups and restores are started from Bacula&rsquo;s console, it can be started with</p>

<pre><code class="`"> sudo bconsole
</code></pre></li>
<li><p>To label the archive file created by the backup job that will be started in a later step use the command</p>

<pre><code class="`"> label
</code></pre>

<p> It will prompt for a name, something like Initial_Backup can be entered.</p></li>
<li><p>Next, the type of storage &ldquo;pool&rdquo;, to store the backup as a <em>File</em>, or archive select option 2 when prompted.</p></li>
<li><p>To begin the backup operation</p>

<pre><code class="`"> run
</code></pre>

<p> Select option 1, <em>BackupClient1</em>, to select the Job configured in the previous steps. This selects a full backup operation since this is the first backup made. If this job is done in the future, an incremental backup will be done. This can be reconfigured in the Job settings.</p></li>
<li><p>To confirm the selections and start the backup type</p>

<pre><code class="`"> yes
</code></pre>

<p> To view output generated by the job use the command</p>

<pre><code class="`"> messages
</code></pre>

<p> When the backup has finished, <em>Backup: OK</em> will be displayed. To exit the console type</p>

<pre><code class="`"> exit
</code></pre></li>
</ol>


<h2>Restoring Files</h2>

<p>When restoring files from a Bacula backup, a full backup must be restored before any incremental backups.</p>

<p>To list all the backup jobs that have been executed use from the Bacula console</p>

<pre><code>list jobs
</code></pre>

<ol>
<li><p>To restore all the files automatically type</p>

<pre><code class="`"> restore all
</code></pre></li>
<li><p>Then use option 5 to select the most recent backup. All files will be preselected from the most recent backup for restoration since <em>all</em> was used. If all is not specified, files can be selected from the tree for restoration.</p></li>
<li><p>To finish file selection type</p>

<pre><code class="`"> done
</code></pre></li>
<li><p>Like during the backup procedure the following can be typed to view generated output</p>

<pre><code class="`"> messages
</code></pre></li>
<li><p>When restoration has been completed type</p>

<pre><code class="`"> exit
</code></pre></li>
</ol>


<p>This covers a very basic restoration process. Documentation for the restore command exists here, for more advanced needs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing phpMyAdmin]]></title>
    <link href="http://boldlycoding.com/blog/2014/12/24/installing-phpmyadmin/"/>
    <updated>2014-12-24T13:30:41-05:00</updated>
    <id>http://boldlycoding.com/blog/2014/12/24/installing-phpmyadmin</id>
    <content type="html"><![CDATA[<!-- more -->


<p>phpMyAdmin simplies the task of database administration for all services running in the cluster. It is also incredibly useful when developing your own applications. Although the command line is still useful for certain DBA tasks, phpMyAdmin makes many faster and easier.</p>

<ol>
<li><p>To begin the installation issue the following command:</p>

<pre><code class="`"> sudo apt-get install phpmyadmin apache2-utils
</code></pre>

<p> Installing apache2-utils allows for the configuration of user restrictions if desired later.</p></li>
<li><p>When prompted, select apache2 to be automatically configured.</p></li>
<li><p>Next, select Yes when asked if dbconfig-common should configure the database. The administrative password for MySQL will be needed.</p></li>
<li><p>Navigate to:</p>

<pre><code class="`"> hostip/phpmyadmin
</code></pre>

<p> The installation should have configured Apache to serve phpMyAdmin. If for some reason phpMyAdmin was inaccessible, inspect:</p>

<pre><code class="`"> /etc/apache2/apache2.conf
</code></pre>

<p> and add, this line if needed</p>

<pre><code class="`"> Include /etc/phpmyadmin/apache.conf
</code></pre>

<p> Then restart apache</p>

<pre><code class="`"> Include /etc/phpmyadmin/apache.conf
</code></pre></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cluster Machine Setup and Prep]]></title>
    <link href="http://boldlycoding.com/blog/2014/12/21/cluster-machine-setup-and-prep/"/>
    <updated>2014-12-21T07:31:53-05:00</updated>
    <id>http://boldlycoding.com/blog/2014/12/21/cluster-machine-setup-and-prep</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>Installing the OS</h2>

<p>All machines in the cluster will use Cloudera Manager, mentioned in a previous post. Cloudera Manager <a href="http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cm_ig_cm_requirements.html" title="Cloudera Manager Requirements">requires</a> that all machines running the manager, and being managed, have a supported 64-bit OS installed. The following process should be followed on all nodes in the cluster</p>

<ol>
<li><p>Through experience I have found that CDH, a component of Cloudera Manager, runs smootly on Ubuntu 12.04 (Precise). Precise can be downloaded <a href="http://releases.ubuntu.com/12.04/" title="Ubuntu 12.04 Download">here</a>. For this project, a server installation was appropriate. There are many web interfaces and no substantial need for a desktop interface.</p></li>
<li><p>Start the OS installation and configure appropriate regional settings including language and keyboard layout.</p></li>
<li><p>The installation will ask for a hostname. All machines in the cluster should have a unique hostname. In my cluster I configured the machines as typhlosion, quilava and cyndaquil where typhlosion is the master of the cluster and the other two machines are slaves.</p>

<p> <img class="center" src="/images/os/3_hostname.png" width="550" height="750" title="Set up each host with an appropiate hostname" ></p></li>
<li><p>The Ubuntu installation will then prompt for a username.</p>

<p> <img class="center" src="/images/os/4_username.png" width="550" height="750" title="Enter an appropriate username" ></p></li>
<li><p>Enter and verify a memorable password.</p>

<p> <img class="center" src="/images/os/5_password.PNG" width="550" height="750" title="Enter an appropriate password" ></p></li>
<li><p>For my project, I chose not to encrypt my home directory.</p>

<p> <img class="center" src="/images/os/6_encrypt.PNG" width="550" height="750" title="Encrypt your directory?" ></p></li>
<li><p>An appropiate time zone should then be selected. I have seen references to problem occurring with CDH/Cloudera Manager when configuration options related to time are not set correctly, so ensure the correct time zone is selected on all machines in the cluster.</p>

<p> <img class="center" src="/images/os/7_timezone.PNG" width="550" height="750" title="Set and appropiate time zone" ></p></li>
<li><p>On the cluster machines, I elected to use the entire disk without LVM for simplicity&rsquo;s sake. Following this step you will need to confirm the disk to partition.</p>

<p> <img class="center" src="/images/os/8_lvm.PNG" width="550" height="750" title="Use LVM?" ></p></li>
<li><p>Finally, the installation will confirm and then write all changes to disk. Assuming everything on your screen is correct, select yes and wait for the files to be written.</p>

<p> <img class="center" src="/images/os/9_write.PNG" width="550" height="750" title="Write changes to disk" ></p></li>
<li><p>Following a lengthy file write, the installation will ask about an HTTP proxy. This was not required for my set up and thus I left the field blank. The installation will then continue writing files.</p></li>
<li><p>The installation now asks about Automatic Updating. Like many tech envoinments where change is not tolerated, Cloudera Manager and Hadoop are no different. Hadoop particularly does not deal well with changes in its environment. Keeping this in mind I selected no automatic updating to use my own discretion, and the installation continued.</p>

<p><img class="center" src="/images/os/11_updates.PNG" width="550" height="750" title="No updates!" ></p></li>
<li><p>Next, software needs to be selected for installation. The spacebar is used for selection and enter confirms selections. The selections will differ based on the type of cluster node. The OpenSSH server <strong>must</strong> be installed on <strong>all</strong> nodes in the cluster. Cloudera Manager and Hadoop use SSH. The LAMP server package should be installed on the master of the cluster (typhlosion in my case) if, like myself, MySQL is more appealing than a PostgreSQL database. Cloudera Manager can store all of its data in a MySQL database and the backup agent Bacula (to be described later) requires a MySQL installation. The slaves of the cluster do not require LAMP to be installed but if more then one of the components are needed, it is not a bad idea to install those now. For my cluster, I only need MySQL on the slaves, so I install that separately to reduce the number of extraneous services. Of course, if any of the other listed components are needed, they should be selected for installation now.</p>

<p><img class="center" src="/images/os/12_software.PNG" width="550" height="750" title="Software selection" ></p></li>
<li><p>If installing MySQL, the installation will display a prompt for a root user password. In this test cluster, I use the same password for all services to simplify the setup process. After entering the password, the installer will request confirmation and then continue writing files.</p>

<p><img class="center" src="/images/os/13_mysqlpassword.PNG" width="550" height="750" title="Enter a MySQL password" ></p></li>
<li><p>Finally, assuming no other OS is detected, select Yes and GRUB will be installed directly to the MBR. I do not recommend running multiple operating systems in a server environment. After GRUB is written the installation will complete and the machine will reboot after Continue is selected.</p>

<p><img class="center" src="/images/os/14_grub.PNG" width="550" height="750" title="Install GRUB" ></p></li>
</ol>


<h2>Configuring the OS</h2>

<p>All nodes in the cluster must be able to communicate with the other nodes. To simplify communication among the cluster nodes, each will be configured with a static IP address. The addresses will then be added to each node&rsquo;s <em>hosts</em> file.</p>

<ol>
<li><p>To configure a static IP address the following command should be issued:</p>

<pre><code class="`"> sudo nano /etc/network/interfaces
</code></pre>

<p> Change the file to (with appropriate addresses for the network):</p>

<pre><code class="`"> auto lo
 iface lo inet loopback

 iface eth0 inet static
 address 10.1.0.113
 gateway 10.1.0.1
 netmask 255.255.255.0
 dns-nameservers 8.8.8.8 8.8.4.4
</code></pre></li>
<li><p>Reboot the machine</p></li>
<li><p>Issue the following command. If everything was configured properly, there will not be any packet loss.</p>

<pre><code class="`"> ping -c 5 www.google.com
</code></pre></li>
<li><p>Repeat the process with the other nodes in the cluster.</p></li>
<li><p>After rebooting the other nodes, the <em>hosts</em> files will need to be edited. On each node issue the following command:</p>

<pre><code class="`"> sudo nano /etc/hosts
</code></pre>

<p> Change the file to:</p>

<pre><code class="`"> 127.0.0.1       localhost
 10.0.2.15       typhlosion typhlosion
</code></pre></li>
<li><p>Attempt to ping nodes from each other using the command</p>

<pre><code class="`"> ping -c 5 hostname
</code></pre></li>
<li><p>For steps later in the cluster setup, it is helpful to have tmux installed. Tmux is a terminal multiplexer and allows the control of multiple programs from one terminal. Also, tmux will save your session in the event of a disconnect. This is very help when installing Cloudera Manager which does not easily tolerate interuptions to the install process. To insatll tmux, run</p>

<pre><code class="`"> sudo apt-get install tmux
</code></pre>

<p> After the OSs on all the nodes in the cluster have been configured, the utility applications phpMyAdmin and Bacula can be installed. PhpMyAdmin will speed up database setup. Bacula creates a backup of the file system that can be restored if something goes wrong later when making changes. Following the installation of these tools, Cloudera Manager can be installed.</p></li>
</ol>

]]></content>
  </entry>
  
</feed>
